{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d20d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新后的权重为: tensor(9.6000, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "演示自动微分模块，具体如何求导\n",
    "\"\"\"\n",
    "\n",
    "# 定义变量，记录出书的权重w旧\n",
    "w = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "w\n",
    "\n",
    "# 定义loss变量，表示损失函数\n",
    "loss = 2 * w**2  # loss = 2w^2 --> 求导：4w\n",
    "loss\n",
    "\n",
    "# 计算梯度\n",
    "# loss.sum().backward() #保证loss是一个标量，才能求导\n",
    "loss.backward()  # 这里因为w本身就是一个标量，所以可以直接求导\n",
    "w.grad\n",
    "\n",
    "# 带入权重更新公式 w新 = w旧 - 学习率 * 梯度\n",
    "lr = 0.01\n",
    "w = w - lr * w.grad\n",
    "\n",
    "print(\"更新后的权重为:\", w) #9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac06b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次，权重初始值:9.800000190734863, 梯度：20.0, loss 120.0\n",
      "第2次，权重初始值:9.604000091552734, 梯度：19.600000381469727, loss 116.04000091552734\n",
      "第3次，权重初始值:9.411920547485352, 梯度：19.20800018310547, loss 112.23681640625\n",
      "第4次，权重初始值:9.223682403564453, 梯度：18.823841094970703, loss 108.5842514038086\n",
      "第5次，权重初始值:9.03920841217041, 梯度：18.447364807128906, loss 105.0763168334961\n",
      "第6次，权重初始值:8.858424186706543, 梯度：18.07841682434082, loss 101.70729064941406\n",
      "第7次，权重初始值:8.681255340576172, 梯度：17.716848373413086, loss 98.4716796875\n",
      "第8次，权重初始值:8.507630348205566, 梯度：17.362510681152344, loss 95.36419677734375\n",
      "第9次，权重初始值:8.337477684020996, 梯度：17.015260696411133, loss 92.37977600097656\n",
      "第10次，权重初始值:8.170727729797363, 梯度：16.674955368041992, loss 89.51353454589844\n",
      "第11次，权重初始值:8.007312774658203, 梯度：16.341455459594727, loss 86.76078796386719\n",
      "第12次，权重初始值:7.847166538238525, 梯度：16.014625549316406, loss 84.11705780029297\n",
      "第13次，权重初始值:7.690223217010498, 梯度：15.69433307647705, loss 81.57801818847656\n",
      "第14次，权重初始值:7.536418914794922, 梯度：15.380446434020996, loss 79.13953399658203\n",
      "第15次，权重初始值:7.385690689086914, 梯度：15.072837829589844, loss 76.797607421875\n",
      "第16次，权重初始值:7.237977027893066, 梯度：14.771381378173828, loss 74.54843139648438\n",
      "第17次，权重初始值:7.093217372894287, 梯度：14.475954055786133, loss 72.38831329345703\n",
      "第18次，权重初始值:6.951353073120117, 梯度：14.186434745788574, loss 70.31373596191406\n",
      "第19次，权重初始值:6.812325954437256, 梯度：13.902706146240234, loss 68.32130432128906\n",
      "第20次，权重初始值:6.676079273223877, 梯度：13.624651908874512, loss 66.40778350830078\n",
      "第21次，权重初始值:6.542557716369629, 梯度：13.352158546447754, loss 64.57003784179688\n",
      "第22次，权重初始值:6.411706447601318, 梯度：13.085115432739258, loss 62.80506134033203\n",
      "第23次，权重初始值:6.283472537994385, 梯度：12.823412895202637, loss 61.10997772216797\n",
      "第24次，权重初始值:6.157803058624268, 梯度：12.56694507598877, loss 59.48202896118164\n",
      "第25次，权重初始值:6.034646987915039, 梯度：12.315606117248535, loss 57.91853713989258\n",
      "第26次，权重初始值:5.913954257965088, 梯度：12.069293975830078, loss 56.41696548461914\n",
      "第27次，权重初始值:5.795675277709961, 梯度：11.827908515930176, loss 54.974853515625\n",
      "第28次，权重初始值:5.67976188659668, 梯度：11.591350555419922, loss 53.58985137939453\n",
      "第29次，权重初始值:5.566166877746582, 梯度：11.35952377319336, loss 52.25969696044922\n",
      "第30次，权重初始值:5.454843521118164, 梯度：11.132333755493164, loss 50.982215881347656\n",
      "第31次，权重初始值:5.3457465171813965, 梯度：10.909687042236328, loss 49.75531768798828\n",
      "第32次，权重初始值:5.238831520080566, 梯度：10.691493034362793, loss 48.577003479003906\n",
      "第33次，权重初始值:5.134054660797119, 梯度：10.477663040161133, loss 47.44535827636719\n",
      "第34次，权重初始值:5.031373500823975, 梯度：10.268109321594238, loss 46.358516693115234\n",
      "第35次，权重初始值:4.930746078491211, 梯度：10.06274700164795, loss 45.314720153808594\n",
      "第36次，权重初始值:4.832131385803223, 梯度：9.861492156982422, loss 44.312255859375\n",
      "第37次，权重初始值:4.7354888916015625, 梯度：9.664262771606445, loss 43.34949493408203\n",
      "第38次，权重初始值:4.6407790184021, 梯度：9.470977783203125, loss 42.42485427856445\n",
      "第39次，权重初始值:4.547963619232178, 梯度：9.2815580368042, loss 41.536827087402344\n",
      "第40次，权重初始值:4.457004547119141, 梯度：9.095927238464355, loss 40.68397521972656\n",
      "第41次，权重初始值:4.367864608764648, 梯度：8.914009094238281, loss 39.864891052246094\n",
      "第42次，权重初始值:4.2805070877075195, 梯度：8.735729217529297, loss 39.07823944091797\n",
      "第43次，权重初始值:4.194897174835205, 梯度：8.561014175415039, loss 38.32273864746094\n",
      "第44次，权重初始值:4.11099910736084, 梯度：8.38979434967041, loss 37.59716033935547\n",
      "第45次，权重初始值:4.028779029846191, 梯度：8.22199821472168, loss 36.90031433105469\n",
      "第46次，权重初始值:3.9482035636901855, 梯度：8.057558059692383, loss 36.23106002807617\n",
      "第47次，权重初始值:3.869239568710327, 梯度：7.896407127380371, loss 35.58831024169922\n",
      "第48次，权重初始值:3.7918548583984375, 梯度：7.738479137420654, loss 34.97101593017578\n",
      "第49次，权重初始值:3.716017723083496, 梯度：7.583709716796875, loss 34.3781623840332\n",
      "第50次，权重初始值:3.641697406768799, 梯度：7.432035446166992, loss 33.80878829956055\n",
      "第51次，权重初始值:3.5688633918762207, 梯度：7.283394813537598, loss 33.261959075927734\n",
      "第52次，权重初始值:3.497486114501953, 梯度：7.137726783752441, loss 32.736785888671875\n",
      "第53次，权重初始值:3.4275364875793457, 梯度：6.994972229003906, loss 32.2324104309082\n",
      "第54次，权重初始值:3.358985662460327, 梯度：6.855072975158691, loss 31.74800682067871\n",
      "第55次，权重初始值:3.2918059825897217, 梯度：6.717971324920654, loss 31.28278350830078\n",
      "第56次，权重初始值:3.2259697914123535, 梯度：6.583611965179443, loss 30.835987091064453\n",
      "第57次，权重初始值:3.1614503860473633, 梯度：6.451939582824707, loss 30.40688133239746\n",
      "第58次，权重初始值:3.0982213020324707, 梯度：6.322900772094727, loss 29.994768142700195\n",
      "第59次，权重初始值:3.036256790161133, 梯度：6.196442604064941, loss 29.598976135253906\n",
      "第60次，权重初始值:2.975531578063965, 梯度：6.072513580322266, loss 29.218854904174805\n",
      "第61次，权重初始值:2.9160208702087402, 梯度：5.95106315612793, loss 28.853788375854492\n",
      "第62次，权重初始值:2.8577003479003906, 梯度：5.8320417404174805, loss 28.503177642822266\n",
      "第63次，权重初始值:2.800546407699585, 梯度：5.715400695800781, loss 28.16645050048828\n",
      "第64次，权重初始值:2.744535446166992, 梯度：5.60109281539917, loss 27.843059539794922\n",
      "第65次，权重初始值:2.6896448135375977, 梯度：5.489070892333984, loss 27.532474517822266\n",
      "第66次，权重初始值:2.6358518600463867, 梯度：5.379289627075195, loss 27.234188079833984\n",
      "第67次，权重初始值:2.583134889602661, 梯度：5.271703720092773, loss 26.947715759277344\n",
      "第68次，权重初始值:2.5314722061157227, 梯度：5.166269779205322, loss 26.67258644104004\n",
      "第69次，权重初始值:2.4808428287506104, 梯度：5.062944412231445, loss 26.40835189819336\n",
      "第70次，权重初始值:2.4312260150909424, 梯度：4.961685657501221, loss 26.15458106994629\n",
      "第71次，权重初始值:2.382601499557495, 梯度：4.862452030181885, loss 25.910860061645508\n",
      "第72次，权重初始值:2.334949493408203, 梯度：4.76520299911499, loss 25.676790237426758\n",
      "第73次，权重初始值:2.28825044631958, 梯度：4.669898986816406, loss 25.451988220214844\n",
      "第74次，权重初始值:2.242485523223877, 梯度：4.57650089263916, loss 25.2360897064209\n",
      "第75次，权重初始值:2.1976358890533447, 梯度：4.484971046447754, loss 25.02874183654785\n",
      "第76次，权重初始值:2.1536831855773926, 梯度：4.3952717781066895, loss 24.82960319519043\n",
      "第77次，权重初始值:2.110609531402588, 梯度：4.307366371154785, loss 24.638351440429688\n",
      "第78次，权重初始值:2.068397283554077, 梯度：4.221219062805176, loss 24.454673767089844\n",
      "第79次，权重初始值:2.027029275894165, 梯度：4.136794567108154, loss 24.27826690673828\n",
      "第80次，权重初始值:1.986488699913025, 梯度：4.05405855178833, loss 24.108848571777344\n",
      "第81次，权重初始值:1.9467589855194092, 梯度：3.97297739982605, loss 23.946136474609375\n",
      "第82次，权重初始值:1.9078238010406494, 梯度：3.8935179710388184, loss 23.789871215820312\n",
      "第83次，权重初始值:1.8696672916412354, 梯度：3.815647602081299, loss 23.63979148864746\n",
      "第84次，权重初始值:1.8322739601135254, 梯度：3.7393345832824707, loss 23.495655059814453\n",
      "第85次，权重初始值:1.7956284284591675, 梯度：3.664547920227051, loss 23.357227325439453\n",
      "第86次，权重初始值:1.7597159147262573, 梯度：3.591256856918335, loss 23.224281311035156\n",
      "第87次，权重初始值:1.7245216369628906, 梯度：3.5194318294525146, loss 23.096599578857422\n",
      "第88次，权重初始值:1.6900311708450317, 梯度：3.4490432739257812, loss 22.973974227905273\n",
      "第89次，权重初始值:1.6562305688858032, 梯度：3.3800623416900635, loss 22.856204986572266\n",
      "第90次，权重初始值:1.6231060028076172, 梯度：3.3124611377716064, loss 22.743099212646484\n",
      "第91次，权重初始值:1.5906438827514648, 梯度：3.2462120056152344, loss 22.63447380065918\n",
      "第92次，权重初始值:1.558830976486206, 梯度：3.1812877655029297, loss 22.530147552490234\n",
      "第93次，权重初始值:1.5276544094085693, 梯度：3.117661952972412, loss 22.429954528808594\n",
      "第94次，权重初始值:1.4971013069152832, 梯度：3.0553088188171387, loss 22.333728790283203\n",
      "第95次，权重初始值:1.4671592712402344, 梯度：2.9942026138305664, loss 22.24131202697754\n",
      "第96次，权重初始值:1.4378161430358887, 梯度：2.9343185424804688, loss 22.152557373046875\n",
      "第97次，权重初始值:1.409059762954712, 梯度：2.8756322860717773, loss 22.06731605529785\n",
      "第98次，权重初始值:1.3808785676956177, 梯度：2.818119525909424, loss 21.985448837280273\n",
      "第99次，权重初始值:1.3532609939575195, 梯度：2.7617571353912354, loss 21.90682601928711\n",
      "第100次，权重初始值:1.3261957168579102, 梯度：2.706521987915039, loss 21.831315994262695\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "演示自动微分，循环实现，计算梯度，更新参数\n",
    "\n",
    "需求：求loss=w**2 + 20的极小值点，并打印y是最小值时w的值（梯度）\n",
    "\"\"\"\n",
    "\n",
    "w = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "loss = w**2 + 20  # 求导loss' = 2w\n",
    "\n",
    "# 迭代100次\n",
    "for i in range(1, 101):\n",
    "    # 正向传播\n",
    "    loss = w**2 + 20\n",
    "    # 梯度清零，默认梯度会累加，需要清零\n",
    "    if w.grad is not None:\n",
    "        w.grad.zero_()\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    # 梯度更新\n",
    "    w.data = w.data - lr * w.grad\n",
    "    # 打印梯度\n",
    "    print(f'第{i}次，权重初始值:{w}, 梯度：{w.grad}, loss {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5ac2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:tensor([10., 20.], requires_grad=True),type:<class 'torch.Tensor'>\n",
      "t2:tensor([10., 20.]),type:<class 'torch.Tensor'>\n",
      "t1:tensor([100.,  20.], requires_grad=True),type:<class 'torch.Tensor'>\n",
      "t2:tensor([100.,  20.]),type:<class 'torch.Tensor'>\n",
      "t1:tensor([100.,  20.], requires_grad=True)True\n",
      "t2:tensor([100.,  20.])False\n",
      "n1:[100.  20.],type:<class 'numpy.ndarray'>\n",
      "n2:[100.  20.],type:<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "将张量转化为ndarray\n",
    "\"\"\"\n",
    "\n",
    "t1 = torch.tensor([10, 20],requires_grad=True,dtype=torch.float32)\n",
    "print(f't1:{t1},type:{type(t1)}')\n",
    "\n",
    "# 尝试把上述的张量转换为numpy数组\n",
    "# t2 = t1.numpy() #直接转换会报错\n",
    "# print(f't1_np:{t1_np},type:{type(t1_np)}')\n",
    "\n",
    "# 解决办法：通过detach函数，将张量从计算图中分离出来，转换为numpy数组\n",
    "t2 = t1.detach()\n",
    "print(f\"t2:{t2},type:{type(t2)}\")\n",
    "\n",
    "# t1和t2共享同一块内存，修改t1会影响t2\n",
    "t1.data[0] = 100\n",
    "print(f\"t1:{t1},type:{type(t1)}\")\n",
    "print(f\"t2:{t2},type:{type(t2)}\")\n",
    "\n",
    "# 查看t1 和 t2 可以自动微分\n",
    "print(f\"t1:{t1}{t1.requires_grad}\")  # True\n",
    "print(f\"t2:{t2}{t2.requires_grad}\")  # False\n",
    "\n",
    "# 转为numpy\n",
    "n1 = t2.numpy()\n",
    "print(f\"n1:{n1},type:{type(n1)}\")\n",
    "\n",
    "# 总结：\n",
    "n2 = t1.detach().numpy()\n",
    "print(f\"n2:{n2},type:{type(n2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2600c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2116,  0.1743,  1.6572],\n",
      "        [-1.4358, -0.9859,  0.9192],\n",
      "        [ 1.9637, -1.0080, -0.7727],\n",
      "        [-0.6106, -1.2267, -0.0430],\n",
      "        [-0.5982,  0.0159,  1.5393]], requires_grad=True)\n",
      "tensor([-0.1323,  0.0406,  1.6879], requires_grad=True)\n",
      "tensor([[-1.0249, -2.9899,  4.9880],\n",
      "        [-1.0249, -2.9899,  4.9880]], grad_fn=<AddBackward0>)\n",
      "tensor(11.6234, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.6832, -1.9932,  3.3254],\n",
      "        [-0.6832, -1.9932,  3.3254],\n",
      "        [-0.6832, -1.9932,  3.3254],\n",
      "        [-0.6832, -1.9932,  3.3254],\n",
      "        [-0.6832, -1.9932,  3.3254]])\n",
      "tensor([-0.6832, -1.9932,  3.3254])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "自动微分模块应用\n",
    "\n",
    "输入数据：两个样本，每个样本5个特征\n",
    "      x1  x2  x3  x4  x5\n",
    "x = [[1., 1., 1., 1., 1.],\n",
    "     [1., 1., 1., 1., 1.]]\n",
    "\n",
    "# 权重\n",
    "w = [[w11, w21, w31],\n",
    "     [w12, w22, w32],\n",
    "     [w13, w23, w33],\n",
    "     [w14, w24, w34],\n",
    "     [w15, w25, w35]]\n",
    "\n",
    "# 偏置\n",
    "b = [b1, b2, b3]\n",
    "\n",
    "输出数据：\n",
    "y = [[0., 0., 0.],\n",
    "     [0., 0., 0.]]\n",
    "\n",
    "y = xw + b\n",
    "\"\"\"\n",
    "\n",
    "# 1.定义x，表示输入数据，假设2行5列，全1矩阵\n",
    "x = torch.ones(2, 5)\n",
    "\n",
    "\n",
    "# 2.定义y,表示标签（真实值），假设2行3列，全0矩阵\n",
    "y = torch.zeros(2, 3)\n",
    "\n",
    "# 3.初始化权重和偏置（自动微分）\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "print(w)\n",
    "print(b)\n",
    "\n",
    "# 4.前向传播，计算出预测值\n",
    "z = torch.matmul(x , w) + b\n",
    "print(z)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = torch.nn.MSELoss() # 均方差\n",
    "loss = criterion(z, y)\n",
    "print(loss)\n",
    "\n",
    "## 5.反向传播，计算梯度\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)\n",
    "\n",
    "## 后续更新梯度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
