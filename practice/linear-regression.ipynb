{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97933cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6944,  0.7738],\n",
      "        [ 1.6396, -0.2964],\n",
      "        [ 0.4554,  0.4080],\n",
      "        ...,\n",
      "        [-0.0500,  1.5169],\n",
      "        [ 0.6530, -0.4187],\n",
      "        [ 0.5703, -0.6491]])\n",
      "tensor([[ 0.1954],\n",
      "        [ 8.4653],\n",
      "        [ 3.7089],\n",
      "        [ 3.9456],\n",
      "        [-0.6695],\n",
      "        [13.9770],\n",
      "        [-0.3597],\n",
      "        [-2.8175],\n",
      "        [-1.4223],\n",
      "        [ 8.8412],\n",
      "        [ 6.7896],\n",
      "        [ 6.7487],\n",
      "        [ 5.3292],\n",
      "        [ 4.5782],\n",
      "        [10.6526],\n",
      "        [ 1.4518],\n",
      "        [ 6.7212],\n",
      "        [ 1.5963],\n",
      "        [ 4.0646],\n",
      "        [ 4.6775],\n",
      "        [10.3512],\n",
      "        [ 6.9679],\n",
      "        [ 5.2602],\n",
      "        [ 2.0682],\n",
      "        [-0.1208],\n",
      "        [ 2.7019],\n",
      "        [10.8969],\n",
      "        [ 5.0784],\n",
      "        [ 4.9086],\n",
      "        [ 9.8659],\n",
      "        [ 6.7782],\n",
      "        [ 8.2578],\n",
      "        [ 1.6140],\n",
      "        [-2.0205],\n",
      "        [ 0.0237],\n",
      "        [13.2781],\n",
      "        [ 4.2559],\n",
      "        [10.1497],\n",
      "        [ 5.5568],\n",
      "        [-0.6380],\n",
      "        [ 9.9893],\n",
      "        [-2.7559],\n",
      "        [ 9.2844],\n",
      "        [ 6.4280],\n",
      "        [ 4.8415],\n",
      "        [-0.3312],\n",
      "        [-2.8648],\n",
      "        [ 7.4945],\n",
      "        [ 5.0155],\n",
      "        [ 0.2590],\n",
      "        [ 7.0520],\n",
      "        [ 1.7912],\n",
      "        [ 4.0842],\n",
      "        [-1.7702],\n",
      "        [-0.4164],\n",
      "        [ 5.9251],\n",
      "        [-1.3598],\n",
      "        [ 3.9729],\n",
      "        [ 2.4534],\n",
      "        [ 5.5048],\n",
      "        [ 4.2189],\n",
      "        [ 6.7272],\n",
      "        [10.2362],\n",
      "        [11.5662],\n",
      "        [ 3.7722],\n",
      "        [ 7.3962],\n",
      "        [ 7.7454],\n",
      "        [ 6.3079],\n",
      "        [ 3.9022],\n",
      "        [ 6.2843],\n",
      "        [10.3640],\n",
      "        [ 1.0005],\n",
      "        [ 8.7870],\n",
      "        [ 2.1174],\n",
      "        [-0.5235],\n",
      "        [-1.8565],\n",
      "        [ 1.5214],\n",
      "        [ 4.7880],\n",
      "        [-0.1288],\n",
      "        [ 8.3510],\n",
      "        [ 5.3215],\n",
      "        [ 2.1971],\n",
      "        [10.0835],\n",
      "        [ 4.3296],\n",
      "        [ 7.3595],\n",
      "        [ 6.0911],\n",
      "        [ 4.7087],\n",
      "        [ 7.2833],\n",
      "        [-1.2485],\n",
      "        [ 8.9896],\n",
      "        [ 3.9199],\n",
      "        [10.3711],\n",
      "        [ 0.0516],\n",
      "        [ 6.1498],\n",
      "        [-2.6444],\n",
      "        [ 3.6161],\n",
      "        [ 3.8080],\n",
      "        [ 2.4814],\n",
      "        [ 9.1760],\n",
      "        [ 3.9258],\n",
      "        [ 5.9885],\n",
      "        [ 6.9967],\n",
      "        [ 6.6986],\n",
      "        [-3.3589],\n",
      "        [ 5.1523],\n",
      "        [-0.7234],\n",
      "        [-0.6416],\n",
      "        [ 3.8395],\n",
      "        [ 4.8209],\n",
      "        [ 9.0051],\n",
      "        [ 6.4805],\n",
      "        [ 7.0309],\n",
      "        [-4.1240],\n",
      "        [13.8954],\n",
      "        [ 5.4276],\n",
      "        [ 3.1347],\n",
      "        [ 5.5098],\n",
      "        [ 1.9091],\n",
      "        [ 2.1897],\n",
      "        [ 2.9074],\n",
      "        [ 4.0097],\n",
      "        [ 3.0094],\n",
      "        [ 6.2444],\n",
      "        [-0.2454],\n",
      "        [ 4.5383],\n",
      "        [ 1.3031],\n",
      "        [12.9626],\n",
      "        [ 0.9158],\n",
      "        [ 3.7642],\n",
      "        [-1.2092],\n",
      "        [ 1.2989],\n",
      "        [ 2.4659],\n",
      "        [ 8.9440],\n",
      "        [ 2.8006],\n",
      "        [ 3.0937],\n",
      "        [11.7953],\n",
      "        [ 4.4153],\n",
      "        [ 3.6044],\n",
      "        [11.4632],\n",
      "        [ 5.8188],\n",
      "        [ 4.4936],\n",
      "        [ 1.7560],\n",
      "        [ 1.9697],\n",
      "        [ 5.7907],\n",
      "        [10.5367],\n",
      "        [ 5.6925],\n",
      "        [ 2.9615],\n",
      "        [ 9.4994],\n",
      "        [ 4.6254],\n",
      "        [-0.9321],\n",
      "        [ 9.6939],\n",
      "        [ 3.2242],\n",
      "        [ 7.5079],\n",
      "        [ 5.8183],\n",
      "        [ 0.6355],\n",
      "        [12.5933],\n",
      "        [ 3.6718],\n",
      "        [ 3.1988],\n",
      "        [ 9.7833],\n",
      "        [ 2.2214],\n",
      "        [ 8.2635],\n",
      "        [ 0.6836],\n",
      "        [ 4.4002],\n",
      "        [ 4.9974],\n",
      "        [ 1.8064],\n",
      "        [ 8.6257],\n",
      "        [ 9.6996],\n",
      "        [ 0.1600],\n",
      "        [ 5.0381],\n",
      "        [ 4.9223],\n",
      "        [ 0.5649],\n",
      "        [ 2.3649],\n",
      "        [-2.5367],\n",
      "        [ 1.7290],\n",
      "        [-0.2597],\n",
      "        [ 3.5375],\n",
      "        [ 5.2917],\n",
      "        [ 0.0652],\n",
      "        [-0.1187],\n",
      "        [ 3.0657],\n",
      "        [ 9.4080],\n",
      "        [-1.2304],\n",
      "        [ 3.5346],\n",
      "        [ 3.8292],\n",
      "        [ 3.9916],\n",
      "        [ 2.9858],\n",
      "        [ 3.1090],\n",
      "        [ 2.1916],\n",
      "        [ 3.4932],\n",
      "        [ 5.0176],\n",
      "        [ 4.4370],\n",
      "        [ 2.0854],\n",
      "        [ 2.0487],\n",
      "        [ 1.8994],\n",
      "        [ 3.9250],\n",
      "        [ 5.2490],\n",
      "        [ 4.9787],\n",
      "        [ 4.8296],\n",
      "        [ 0.9292],\n",
      "        [ 7.8010],\n",
      "        [ 5.8303],\n",
      "        [-0.5105],\n",
      "        [ 0.7889],\n",
      "        [ 1.6462],\n",
      "        [-0.9132],\n",
      "        [ 5.6126],\n",
      "        [ 3.5816],\n",
      "        [ 2.9307],\n",
      "        [ 5.7255],\n",
      "        [-1.3016],\n",
      "        [ 0.7641],\n",
      "        [ 3.7613],\n",
      "        [ 1.0226],\n",
      "        [ 0.7215],\n",
      "        [ 5.7525],\n",
      "        [ 3.3771],\n",
      "        [ 1.3536],\n",
      "        [ 9.8645],\n",
      "        [-3.7726],\n",
      "        [ 2.1435],\n",
      "        [ 3.4466],\n",
      "        [ 1.5858],\n",
      "        [ 7.0800],\n",
      "        [ 0.7789],\n",
      "        [ 9.1951],\n",
      "        [ 5.4427],\n",
      "        [ 4.0505],\n",
      "        [ 2.4374],\n",
      "        [ 1.8019],\n",
      "        [ 8.6166],\n",
      "        [ 1.5133],\n",
      "        [ 1.6222],\n",
      "        [ 4.2980],\n",
      "        [ 4.3444],\n",
      "        [ 8.8709],\n",
      "        [-3.6452],\n",
      "        [ 0.1901],\n",
      "        [ 8.4091],\n",
      "        [ 3.0967],\n",
      "        [ 5.3025],\n",
      "        [ 3.1083],\n",
      "        [-0.6536],\n",
      "        [ 2.6240],\n",
      "        [ 0.9041],\n",
      "        [ 3.1997],\n",
      "        [ 1.7024],\n",
      "        [ 5.5548],\n",
      "        [ 7.5565],\n",
      "        [ 3.3013],\n",
      "        [ 1.0680],\n",
      "        [ 6.8260],\n",
      "        [ 2.3067],\n",
      "        [ 1.4559],\n",
      "        [ 4.8245],\n",
      "        [ 1.6184],\n",
      "        [ 0.2911],\n",
      "        [ 6.2056],\n",
      "        [ 3.3651],\n",
      "        [ 2.5794],\n",
      "        [ 2.0953],\n",
      "        [ 7.8248],\n",
      "        [ 1.2055],\n",
      "        [ 3.4866],\n",
      "        [ 4.9901],\n",
      "        [-0.4321],\n",
      "        [ 8.2448],\n",
      "        [ 2.5207],\n",
      "        [14.7931],\n",
      "        [-0.0487],\n",
      "        [ 6.0314],\n",
      "        [ 7.0668],\n",
      "        [ 2.2602],\n",
      "        [-2.2007],\n",
      "        [ 7.9348],\n",
      "        [ 9.3964],\n",
      "        [ 3.7510],\n",
      "        [-5.4189],\n",
      "        [ 1.8017],\n",
      "        [ 0.3669],\n",
      "        [ 1.1005],\n",
      "        [ 4.2394],\n",
      "        [ 3.6082],\n",
      "        [ 1.3422],\n",
      "        [ 0.3593],\n",
      "        [ 3.2444],\n",
      "        [ 4.0975],\n",
      "        [10.3026],\n",
      "        [-2.8473],\n",
      "        [-4.9621],\n",
      "        [ 7.2881],\n",
      "        [ 2.2194],\n",
      "        [ 5.4921],\n",
      "        [-0.6552],\n",
      "        [ 5.5176],\n",
      "        [ 5.8135],\n",
      "        [ 2.1661],\n",
      "        [ 4.5589],\n",
      "        [-1.9426],\n",
      "        [-4.2277],\n",
      "        [ 7.2859],\n",
      "        [ 4.8940],\n",
      "        [ 9.9802],\n",
      "        [-2.6971],\n",
      "        [ 4.7847],\n",
      "        [ 6.6203],\n",
      "        [ 1.3450],\n",
      "        [10.4221],\n",
      "        [ 1.4051],\n",
      "        [ 5.9591],\n",
      "        [ 5.8805],\n",
      "        [ 2.9302],\n",
      "        [11.6750],\n",
      "        [-0.0313],\n",
      "        [ 5.3372],\n",
      "        [-1.0918],\n",
      "        [-3.6985],\n",
      "        [10.5345],\n",
      "        [-6.3193],\n",
      "        [ 5.8397],\n",
      "        [ 4.6229],\n",
      "        [-2.4264],\n",
      "        [ 3.3132],\n",
      "        [ 7.3691],\n",
      "        [ 7.8396],\n",
      "        [ 4.7150],\n",
      "        [-2.1713],\n",
      "        [ 4.4772],\n",
      "        [ 1.0326],\n",
      "        [ 4.7982],\n",
      "        [ 3.7199],\n",
      "        [ 4.0610],\n",
      "        [-1.2067],\n",
      "        [ 3.4086],\n",
      "        [ 6.4246],\n",
      "        [ 3.7851],\n",
      "        [ 4.9855],\n",
      "        [ 3.1778],\n",
      "        [ 8.4951],\n",
      "        [13.3697],\n",
      "        [ 8.3244],\n",
      "        [ 2.5886],\n",
      "        [ 3.9749],\n",
      "        [ 0.5798],\n",
      "        [ 7.0623],\n",
      "        [-0.9488],\n",
      "        [ 5.2517],\n",
      "        [ 9.1316],\n",
      "        [ 4.5604],\n",
      "        [ 6.7990],\n",
      "        [ 4.3084],\n",
      "        [ 5.3771],\n",
      "        [ 5.3739],\n",
      "        [ 1.7790],\n",
      "        [ 6.8328],\n",
      "        [ 4.1476],\n",
      "        [ 3.2205],\n",
      "        [ 3.7820],\n",
      "        [-0.2524],\n",
      "        [15.4094],\n",
      "        [ 9.3796],\n",
      "        [-3.0611],\n",
      "        [ 2.6488],\n",
      "        [-0.0175],\n",
      "        [11.1109],\n",
      "        [-1.2317],\n",
      "        [-0.0756],\n",
      "        [ 4.1135],\n",
      "        [-1.9858],\n",
      "        [ 1.4411],\n",
      "        [ 7.4744],\n",
      "        [ 9.1876],\n",
      "        [ 3.3091],\n",
      "        [ 7.4269],\n",
      "        [ 3.6402],\n",
      "        [ 7.9329],\n",
      "        [ 1.3184],\n",
      "        [ 7.3177],\n",
      "        [ 4.2848],\n",
      "        [ 8.7044],\n",
      "        [ 4.7329],\n",
      "        [ 9.2224],\n",
      "        [ 3.3734],\n",
      "        [ 3.8268],\n",
      "        [ 8.2194],\n",
      "        [ 5.0755],\n",
      "        [ 5.8400],\n",
      "        [ 4.0965],\n",
      "        [ 4.5620],\n",
      "        [10.5364],\n",
      "        [ 1.9693],\n",
      "        [ 3.8006],\n",
      "        [ 3.9620],\n",
      "        [ 4.7515],\n",
      "        [10.1099],\n",
      "        [10.7348],\n",
      "        [ 2.7256],\n",
      "        [ 4.6617],\n",
      "        [ 0.8315],\n",
      "        [ 0.0766],\n",
      "        [-0.1041],\n",
      "        [ 1.7370],\n",
      "        [ 6.3034],\n",
      "        [14.5355],\n",
      "        [ 7.7877],\n",
      "        [ 6.5485],\n",
      "        [-0.3705],\n",
      "        [ 0.6174],\n",
      "        [ 0.6878],\n",
      "        [ 0.9023],\n",
      "        [-0.6906],\n",
      "        [ 0.5284],\n",
      "        [ 5.6113],\n",
      "        [ 3.5933],\n",
      "        [ 5.4312],\n",
      "        [ 5.2237],\n",
      "        [ 1.5608],\n",
      "        [-1.8008],\n",
      "        [ 4.7168],\n",
      "        [ 1.8453],\n",
      "        [ 1.3587],\n",
      "        [ 6.2946],\n",
      "        [ 3.1866],\n",
      "        [ 5.2748],\n",
      "        [ 5.5666],\n",
      "        [-3.5296],\n",
      "        [ 4.8611],\n",
      "        [ 1.1251],\n",
      "        [ 4.5663],\n",
      "        [ 8.6069],\n",
      "        [-0.4480],\n",
      "        [ 7.2528],\n",
      "        [ 2.4516],\n",
      "        [ 7.5530],\n",
      "        [ 9.3116],\n",
      "        [ 1.8629],\n",
      "        [ 1.4130],\n",
      "        [-2.1343],\n",
      "        [ 1.6744],\n",
      "        [ 5.3505],\n",
      "        [13.9819],\n",
      "        [ 0.8407],\n",
      "        [ 1.3534],\n",
      "        [ 6.1515],\n",
      "        [ 9.2181],\n",
      "        [11.8247],\n",
      "        [ 8.2703],\n",
      "        [ 6.0852],\n",
      "        [ 7.2574],\n",
      "        [ 4.1791],\n",
      "        [11.9471],\n",
      "        [ 7.3636],\n",
      "        [-1.4225],\n",
      "        [ 5.0451],\n",
      "        [ 4.8398],\n",
      "        [ 9.8361],\n",
      "        [ 1.1026],\n",
      "        [ 7.4115],\n",
      "        [ 2.6663],\n",
      "        [-2.4399],\n",
      "        [-1.9914],\n",
      "        [ 0.9871],\n",
      "        [-1.8317],\n",
      "        [-3.6909],\n",
      "        [-0.6280],\n",
      "        [ 3.3417],\n",
      "        [ 4.5952],\n",
      "        [ 6.3642],\n",
      "        [ 2.6124],\n",
      "        [ 2.1040],\n",
      "        [ 1.3120],\n",
      "        [ 2.8017],\n",
      "        [ 1.5730],\n",
      "        [ 4.7925],\n",
      "        [ 6.7021],\n",
      "        [ 6.8816],\n",
      "        [ 9.4715],\n",
      "        [-0.0533],\n",
      "        [ 7.9267],\n",
      "        [-0.4488],\n",
      "        [ 3.0468],\n",
      "        [10.3538],\n",
      "        [ 4.7382],\n",
      "        [ 2.7907],\n",
      "        [ 6.9042],\n",
      "        [ 2.4689],\n",
      "        [ 7.9392],\n",
      "        [ 7.4577],\n",
      "        [ 7.3878],\n",
      "        [ 3.6186],\n",
      "        [ 1.3652],\n",
      "        [ 7.5431],\n",
      "        [ 3.7168],\n",
      "        [-2.9545],\n",
      "        [ 3.8814],\n",
      "        [ 2.1726],\n",
      "        [10.9511],\n",
      "        [ 6.2280],\n",
      "        [ 1.2766],\n",
      "        [ 5.4941],\n",
      "        [ 9.6010],\n",
      "        [ 3.7456],\n",
      "        [ 3.6050],\n",
      "        [ 4.0507],\n",
      "        [ 8.0039],\n",
      "        [10.8324],\n",
      "        [ 5.3664],\n",
      "        [ 9.3952],\n",
      "        [ 5.1450],\n",
      "        [-0.4113],\n",
      "        [-0.1122],\n",
      "        [ 8.0179],\n",
      "        [ 4.7356],\n",
      "        [ 7.1668],\n",
      "        [ 0.6096],\n",
      "        [ 2.2390],\n",
      "        [ 3.3741],\n",
      "        [ 4.0991],\n",
      "        [ 9.3761],\n",
      "        [ 7.3936],\n",
      "        [-4.0322],\n",
      "        [ 5.5940],\n",
      "        [ 6.7582],\n",
      "        [13.5229],\n",
      "        [ 1.9320],\n",
      "        [ 2.9493],\n",
      "        [-1.9917],\n",
      "        [ 7.8941],\n",
      "        [-4.4724],\n",
      "        [ 4.6171],\n",
      "        [ 7.7274],\n",
      "        [ 3.6453],\n",
      "        [ 5.0071],\n",
      "        [ 3.4231],\n",
      "        [-1.7306],\n",
      "        [ 9.2035],\n",
      "        [ 9.3369],\n",
      "        [ 7.1786],\n",
      "        [ 4.1102],\n",
      "        [ 5.7279],\n",
      "        [ 5.5735],\n",
      "        [ 6.9022],\n",
      "        [ 7.4549],\n",
      "        [ 9.8745],\n",
      "        [ 7.8639],\n",
      "        [ 3.3053],\n",
      "        [ 4.4988],\n",
      "        [ 5.8076],\n",
      "        [ 4.0884],\n",
      "        [ 1.4833],\n",
      "        [ 7.1605],\n",
      "        [ 5.2373],\n",
      "        [ 5.2064],\n",
      "        [ 3.7254],\n",
      "        [ 4.6821],\n",
      "        [-1.1791],\n",
      "        [ 6.6543],\n",
      "        [-1.9117],\n",
      "        [ 3.7495],\n",
      "        [10.6040],\n",
      "        [ 1.0671],\n",
      "        [ 7.2611],\n",
      "        [ 3.3247],\n",
      "        [ 7.8416],\n",
      "        [ 3.0303],\n",
      "        [ 3.5684],\n",
      "        [ 0.7622],\n",
      "        [ 5.7550],\n",
      "        [ 8.8560],\n",
      "        [ 3.9770],\n",
      "        [ 4.0411],\n",
      "        [ 1.3841],\n",
      "        [ 9.0797],\n",
      "        [ 7.9221],\n",
      "        [12.5570],\n",
      "        [ 5.1189],\n",
      "        [ 6.6308],\n",
      "        [ 4.2672],\n",
      "        [ 2.8317],\n",
      "        [ 4.3951],\n",
      "        [ 8.5555],\n",
      "        [-0.6661],\n",
      "        [ 3.0188],\n",
      "        [ 9.7204],\n",
      "        [ 9.0889],\n",
      "        [ 1.1616],\n",
      "        [ 0.9627],\n",
      "        [ 6.9528],\n",
      "        [ 4.4283],\n",
      "        [ 3.7314],\n",
      "        [ 2.7133],\n",
      "        [ 1.6548],\n",
      "        [ 4.9254],\n",
      "        [ 1.0975],\n",
      "        [ 1.7966],\n",
      "        [13.6540],\n",
      "        [ 4.8005],\n",
      "        [ 5.6689],\n",
      "        [ 3.7638],\n",
      "        [ 5.5914],\n",
      "        [ 2.6616],\n",
      "        [ 1.8805],\n",
      "        [-1.3827],\n",
      "        [ 7.3083],\n",
      "        [ 6.5606],\n",
      "        [ 2.7587],\n",
      "        [ 0.9818],\n",
      "        [ 1.4976],\n",
      "        [ 1.0352],\n",
      "        [ 1.9398],\n",
      "        [ 4.5892],\n",
      "        [ 0.9298],\n",
      "        [-1.6845],\n",
      "        [ 2.9140],\n",
      "        [ 8.4057],\n",
      "        [ 6.1959],\n",
      "        [ 5.8259],\n",
      "        [-1.3506],\n",
      "        [ 9.4295],\n",
      "        [-3.5882],\n",
      "        [10.5404],\n",
      "        [-0.8654],\n",
      "        [ 1.2307],\n",
      "        [10.3477],\n",
      "        [-1.5384],\n",
      "        [-0.3565],\n",
      "        [ 5.4734],\n",
      "        [ 7.6201],\n",
      "        [ 0.1924],\n",
      "        [ 6.3291],\n",
      "        [11.0237],\n",
      "        [ 9.3486],\n",
      "        [ 0.1171],\n",
      "        [ 6.0923],\n",
      "        [ 9.9039],\n",
      "        [ 3.4873],\n",
      "        [-1.2766],\n",
      "        [ 4.7644],\n",
      "        [ 1.8923],\n",
      "        [ 7.5537],\n",
      "        [ 1.8172],\n",
      "        [ 9.5525],\n",
      "        [-3.6901],\n",
      "        [ 6.9060],\n",
      "        [ 7.8970],\n",
      "        [ 2.3526],\n",
      "        [ 2.3753],\n",
      "        [ 1.2380],\n",
      "        [ 1.4677],\n",
      "        [10.2390],\n",
      "        [ 0.5873],\n",
      "        [12.8861],\n",
      "        [ 2.0874],\n",
      "        [ 3.9227],\n",
      "        [ 9.9658],\n",
      "        [ 1.3596],\n",
      "        [ 3.5910],\n",
      "        [ 7.4037],\n",
      "        [ 1.8308],\n",
      "        [-0.1689],\n",
      "        [-4.1336],\n",
      "        [-0.1809],\n",
      "        [ 6.2497],\n",
      "        [ 2.8034],\n",
      "        [ 4.3878],\n",
      "        [ 4.3720],\n",
      "        [ 3.3094],\n",
      "        [-3.8505],\n",
      "        [ 0.4786],\n",
      "        [ 6.1881],\n",
      "        [ 0.1460],\n",
      "        [ 9.6356],\n",
      "        [ 8.1238],\n",
      "        [ 7.0556],\n",
      "        [ 1.4801],\n",
      "        [ 3.8669],\n",
      "        [ 3.4254],\n",
      "        [-1.6498],\n",
      "        [-1.6577],\n",
      "        [10.5992],\n",
      "        [ 4.1531],\n",
      "        [ 0.8477],\n",
      "        [ 6.0396],\n",
      "        [ 4.2289],\n",
      "        [-0.5943],\n",
      "        [ 4.3313],\n",
      "        [-4.5136],\n",
      "        [-2.3445],\n",
      "        [ 5.9961],\n",
      "        [ 5.1703],\n",
      "        [ 8.0201],\n",
      "        [ 8.4567],\n",
      "        [ 5.9079],\n",
      "        [ 9.6091],\n",
      "        [ 6.5679],\n",
      "        [-3.6642],\n",
      "        [ 4.1602],\n",
      "        [ 0.6702],\n",
      "        [ 9.0040],\n",
      "        [ 3.5742],\n",
      "        [-0.0455],\n",
      "        [-3.1150],\n",
      "        [ 5.4293],\n",
      "        [ 6.5144],\n",
      "        [-0.0215],\n",
      "        [-2.8919],\n",
      "        [ 6.6627],\n",
      "        [-5.0456],\n",
      "        [ 5.2172],\n",
      "        [ 5.6296],\n",
      "        [ 5.9321],\n",
      "        [ 3.0642],\n",
      "        [ 7.5702],\n",
      "        [10.4356],\n",
      "        [ 4.1545],\n",
      "        [ 8.5169],\n",
      "        [-0.0503],\n",
      "        [-6.2325],\n",
      "        [ 6.8670],\n",
      "        [ 4.9359],\n",
      "        [ 4.5772],\n",
      "        [ 9.5731],\n",
      "        [ 3.5960],\n",
      "        [-0.0412],\n",
      "        [-1.4509],\n",
      "        [ 4.6195],\n",
      "        [ 3.1171],\n",
      "        [ 4.4520],\n",
      "        [-0.1216],\n",
      "        [ 4.2935],\n",
      "        [ 0.6725],\n",
      "        [ 7.0895],\n",
      "        [ 4.4421],\n",
      "        [-1.1463],\n",
      "        [ 3.8044],\n",
      "        [ 5.1924],\n",
      "        [ 0.2511],\n",
      "        [12.4362],\n",
      "        [ 9.6106],\n",
      "        [11.1154],\n",
      "        [ 4.1223],\n",
      "        [ 4.7936],\n",
      "        [ 4.6470],\n",
      "        [ 4.6774],\n",
      "        [ 6.2291],\n",
      "        [-1.5436],\n",
      "        [ 5.9441],\n",
      "        [ 2.9381],\n",
      "        [ 2.5321],\n",
      "        [-0.4483],\n",
      "        [12.9995],\n",
      "        [ 2.0550],\n",
      "        [-3.8433],\n",
      "        [ 1.3336],\n",
      "        [ 7.8553],\n",
      "        [12.5291],\n",
      "        [ 5.2110],\n",
      "        [ 5.6185],\n",
      "        [ 4.7563],\n",
      "        [-1.6004],\n",
      "        [ 5.4190],\n",
      "        [ 3.2490],\n",
      "        [ 4.8373],\n",
      "        [ 4.6389],\n",
      "        [ 4.8303],\n",
      "        [ 5.2177],\n",
      "        [11.0783],\n",
      "        [-4.0287],\n",
      "        [ 7.5234],\n",
      "        [-1.0672],\n",
      "        [-2.5836],\n",
      "        [12.2714],\n",
      "        [ 5.8261],\n",
      "        [ 5.2567],\n",
      "        [-0.4602],\n",
      "        [-0.8508],\n",
      "        [ 4.6473],\n",
      "        [ 8.3648],\n",
      "        [-0.8944],\n",
      "        [ 0.8900],\n",
      "        [ 2.7857],\n",
      "        [ 5.3805],\n",
      "        [ 3.4448],\n",
      "        [ 3.4260],\n",
      "        [-0.7745],\n",
      "        [ 4.6158],\n",
      "        [ 1.7442],\n",
      "        [ 0.3687],\n",
      "        [-0.3682],\n",
      "        [ 2.9580],\n",
      "        [-0.2404],\n",
      "        [ 7.2361],\n",
      "        [ 0.4687],\n",
      "        [ 8.1251],\n",
      "        [ 4.1489],\n",
      "        [-2.7960],\n",
      "        [ 8.5958],\n",
      "        [ 6.6814],\n",
      "        [ 7.4711],\n",
      "        [ 6.4023],\n",
      "        [ 0.6851],\n",
      "        [ 2.7437],\n",
      "        [ 2.8325],\n",
      "        [ 2.8267],\n",
      "        [ 7.1191],\n",
      "        [ 1.1899],\n",
      "        [ 2.3707],\n",
      "        [ 3.8140],\n",
      "        [ 1.2616],\n",
      "        [ 5.6354],\n",
      "        [ 8.4720],\n",
      "        [ 9.4233],\n",
      "        [14.3355],\n",
      "        [ 0.0987],\n",
      "        [ 6.8051],\n",
      "        [ 0.2311],\n",
      "        [ 3.2939],\n",
      "        [ 8.0318],\n",
      "        [ 0.5002],\n",
      "        [ 2.7816],\n",
      "        [ 4.6330],\n",
      "        [10.8015],\n",
      "        [ 0.4073],\n",
      "        [ 7.9367],\n",
      "        [ 0.5159],\n",
      "        [ 9.9221],\n",
      "        [-3.0483],\n",
      "        [ 7.7773],\n",
      "        [ 2.5654],\n",
      "        [ 9.5359],\n",
      "        [ 7.2562],\n",
      "        [ 5.8254],\n",
      "        [ 4.1784],\n",
      "        [ 5.7870],\n",
      "        [ 8.8336],\n",
      "        [ 5.4990],\n",
      "        [11.0015],\n",
      "        [ 6.8215],\n",
      "        [-2.5112],\n",
      "        [ 0.6187],\n",
      "        [ 7.9043],\n",
      "        [ 6.5999],\n",
      "        [ 4.0599],\n",
      "        [ 4.2702],\n",
      "        [ 2.0934],\n",
      "        [-1.4634],\n",
      "        [ 2.0695],\n",
      "        [ 1.9480],\n",
      "        [ 4.5803],\n",
      "        [ 5.5242],\n",
      "        [ 6.7342],\n",
      "        [11.0414],\n",
      "        [ 9.9669],\n",
      "        [ 0.8371],\n",
      "        [ 2.5990],\n",
      "        [ 5.9800],\n",
      "        [ 1.6108],\n",
      "        [-3.4599],\n",
      "        [ 7.6196],\n",
      "        [ 6.9774],\n",
      "        [ 4.1770],\n",
      "        [ 7.6669],\n",
      "        [ 7.0295],\n",
      "        [10.8900],\n",
      "        [ 3.1679],\n",
      "        [ 3.8102],\n",
      "        [11.8294],\n",
      "        [ 2.8258],\n",
      "        [ 8.9085],\n",
      "        [ 7.6394],\n",
      "        [ 7.5150],\n",
      "        [ 5.9123],\n",
      "        [ 5.3553],\n",
      "        [-3.3786],\n",
      "        [ 3.8424],\n",
      "        [ 6.7104],\n",
      "        [ 2.8307],\n",
      "        [ 8.0453],\n",
      "        [ 4.4699],\n",
      "        [ 3.3093],\n",
      "        [ 8.1900],\n",
      "        [ 3.0627],\n",
      "        [ 5.5939],\n",
      "        [ 5.8213],\n",
      "        [ 0.3959],\n",
      "        [11.7349],\n",
      "        [-0.2272],\n",
      "        [ 3.7989],\n",
      "        [ 1.0050],\n",
      "        [ 7.8011],\n",
      "        [ 2.5497],\n",
      "        [ 2.2465],\n",
      "        [15.3695],\n",
      "        [ 5.8555],\n",
      "        [-1.3996],\n",
      "        [ 1.9127],\n",
      "        [-0.2216],\n",
      "        [ 5.9475],\n",
      "        [ 5.5909],\n",
      "        [ 3.2225],\n",
      "        [ 9.5241],\n",
      "        [ 7.7295],\n",
      "        [11.1300],\n",
      "        [-1.8068],\n",
      "        [ 6.1223],\n",
      "        [-3.5733],\n",
      "        [ 5.5742],\n",
      "        [ 3.9484],\n",
      "        [ 5.1291],\n",
      "        [ 7.6686],\n",
      "        [ 3.2521],\n",
      "        [ 5.3225],\n",
      "        [ 2.6240],\n",
      "        [ 2.6907],\n",
      "        [ 7.5084],\n",
      "        [ 5.9132],\n",
      "        [ 9.4163],\n",
      "        [-1.2233],\n",
      "        [ 6.0967],\n",
      "        [ 4.1672],\n",
      "        [ 1.4497],\n",
      "        [ 5.0365],\n",
      "        [ 5.4709],\n",
      "        [ 6.1149],\n",
      "        [-2.2071],\n",
      "        [ 0.9544],\n",
      "        [ 5.4807],\n",
      "        [ 5.9515],\n",
      "        [ 5.4627],\n",
      "        [ 2.6834],\n",
      "        [ 4.3332],\n",
      "        [ 1.7527],\n",
      "        [ 4.7430],\n",
      "        [-3.8365],\n",
      "        [ 3.8891],\n",
      "        [ 0.3325],\n",
      "        [ 3.3150],\n",
      "        [ 6.5060],\n",
      "        [ 4.9568],\n",
      "        [10.2118],\n",
      "        [ 1.7341],\n",
      "        [ 4.4803],\n",
      "        [ 3.5104],\n",
      "        [ 5.0253],\n",
      "        [ 0.6861],\n",
      "        [11.6143],\n",
      "        [ 4.6901],\n",
      "        [ 4.4259],\n",
      "        [-0.1856],\n",
      "        [ 8.3356],\n",
      "        [ 1.4236],\n",
      "        [ 6.3190],\n",
      "        [-3.9306],\n",
      "        [ 3.3417],\n",
      "        [-0.7545],\n",
      "        [-2.2931],\n",
      "        [-2.5702],\n",
      "        [ 1.6376],\n",
      "        [-0.8102],\n",
      "        [ 6.2432],\n",
      "        [12.1579],\n",
      "        [ 8.8437],\n",
      "        [-0.7217],\n",
      "        [ 6.3709],\n",
      "        [ 7.3009],\n",
      "        [ 4.7620],\n",
      "        [ 5.0466],\n",
      "        [10.9199],\n",
      "        [ 1.4587],\n",
      "        [ 7.6224],\n",
      "        [10.4708],\n",
      "        [ 2.9203],\n",
      "        [ 0.3712],\n",
      "        [ 5.2013],\n",
      "        [ 4.9232],\n",
      "        [-7.1993],\n",
      "        [-3.0843],\n",
      "        [ 2.4575],\n",
      "        [ 3.8187],\n",
      "        [ 5.6924],\n",
      "        [ 4.4512],\n",
      "        [ 1.6042],\n",
      "        [ 3.0392],\n",
      "        [ 6.5189],\n",
      "        [ 5.8732],\n",
      "        [ 1.4400],\n",
      "        [ 6.5302],\n",
      "        [ 4.3112],\n",
      "        [ 9.1888],\n",
      "        [ 3.1702],\n",
      "        [-0.7281],\n",
      "        [12.0698],\n",
      "        [ 8.2584],\n",
      "        [ 5.9987],\n",
      "        [11.0570],\n",
      "        [-2.0738],\n",
      "        [ 8.2272],\n",
      "        [ 0.3615],\n",
      "        [-1.0762],\n",
      "        [ 6.9280],\n",
      "        [ 7.5559]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "\n",
    "# 生成数据集\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    # 生成1000个样本数据：shape为1000 * 2样本矩阵\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    # print(X \n",
    "    y = torch.matmul(X, w) + b\n",
    "    # print(y)\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    # y =Xw + b + c c为潜在观测误差\n",
    "    return X, y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "print(features)  # 样本数据\n",
    "print(labels)  # 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524f76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4694, -0.3411],\n",
      "        [ 0.1128, -1.4113],\n",
      "        [ 1.3694, -0.1044],\n",
      "        [ 0.5780,  0.9316],\n",
      "        [ 0.0655, -1.1766],\n",
      "        [-1.6838, -0.4678],\n",
      "        [-2.5279,  0.5063],\n",
      "        [ 0.2774, -1.3928],\n",
      "        [ 1.2147,  0.3311],\n",
      "        [-1.6394,  0.0222]]) \n",
      " tensor([[ 6.2946],\n",
      "        [ 9.2224],\n",
      "        [ 7.2859],\n",
      "        [ 2.1897],\n",
      "        [ 8.3244],\n",
      "        [ 2.4374],\n",
      "        [-2.5702],\n",
      "        [ 9.4715],\n",
      "        [ 5.5048],\n",
      "        [ 0.8315]])\n"
     ]
    }
   ],
   "source": [
    "# 小批量抽取样本数据\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples)) \n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)  # 打乱索引顺序\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i : min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, \"\\n\", y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7931eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0202],\n",
      "        [-0.0137]], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型参数\n",
    "w = torch.normal(0,0.01,size=(2,1),requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(w)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ff5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.042961\n",
      "epoch 2, loss 0.000167\n",
      "epoch 3, loss 0.000046\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "def linreg(X, w, b):\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b\n",
    "\n",
    "# 定义损失函数\n",
    "def square_loss(y_hat, y):\n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n",
    "\n",
    "# 定义优化算法\n",
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():  # 用来临时关闭 PyTorch 的自动求导机制\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "lr = 0.03  \n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = square_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "\n",
    "    # 输出查看w,b更新后的损失值\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
